{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Setup\n",
    "Use this dataset of airline arrival information to predict how late flights will be. A flight only counts as late if it is more than 30 minutes late.\n",
    "\n",
    "I am going to treat this problem as a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbohan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\sbohan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "from sklearn import grid_search\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('2008.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#right away I can tell that this is a large data set that will require long processing times. let's take a random sample\n",
    "flights = df.sample(frac=0.05)\n",
    "\n",
    "#pros and cons- increasing processing speed, but cons randoemly removing data\n",
    "#might be valuable insights into data\n",
    "\n",
    "#when prototyping, doing this on subset of data is fine, but in the end during oproduction, would want to train on full data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 350486 entries, 5146665 to 6760897\n",
      "Data columns (total 29 columns):\n",
      "Year                 350486 non-null int64\n",
      "Month                350486 non-null int64\n",
      "DayofMonth           350486 non-null int64\n",
      "DayOfWeek            350486 non-null int64\n",
      "DepTime              343752 non-null float64\n",
      "CRSDepTime           350486 non-null int64\n",
      "ArrTime              342948 non-null float64\n",
      "CRSArrTime           350486 non-null int64\n",
      "UniqueCarrier        350486 non-null object\n",
      "FlightNum            350486 non-null int64\n",
      "TailNum              346343 non-null object\n",
      "ActualElapsedTime    342784 non-null float64\n",
      "CRSElapsedTime       350442 non-null float64\n",
      "AirTime              342784 non-null float64\n",
      "ArrDelay             342784 non-null float64\n",
      "DepDelay             343752 non-null float64\n",
      "Origin               350486 non-null object\n",
      "Dest                 350486 non-null object\n",
      "Distance             350486 non-null int64\n",
      "TaxiIn               342948 non-null float64\n",
      "TaxiOut              343702 non-null float64\n",
      "Cancelled            350486 non-null int64\n",
      "CancellationCode     6803 non-null object\n",
      "Diverted             350486 non-null int64\n",
      "CarrierDelay         76180 non-null float64\n",
      "WeatherDelay         76180 non-null float64\n",
      "NASDelay             76180 non-null float64\n",
      "SecurityDelay        76180 non-null float64\n",
      "LateAircraftDelay    76180 non-null float64\n",
      "dtypes: float64(14), int64(10), object(5)\n",
      "memory usage: 80.2+ MB\n"
     ]
    }
   ],
   "source": [
    "flights.info()\n",
    "\n",
    "#could limit data set by selectinng certain airports or carriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>...</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1016</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>1142</td>\n",
       "      <td>EV</td>\n",
       "      <td>4761</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>2107</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2356</td>\n",
       "      <td>NW</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>1045</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1210</td>\n",
       "      <td>WN</td>\n",
       "      <td>664</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2359</td>\n",
       "      <td>824.0</td>\n",
       "      <td>815</td>\n",
       "      <td>B6</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2139.0</td>\n",
       "      <td>2139</td>\n",
       "      <td>US</td>\n",
       "      <td>1007</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  \\\n",
       "0  2008      9          21          7   1015.0        1016   1141.0   \n",
       "1  2008      5           1          4   2130.0        2107     33.0   \n",
       "2  2008      4          16          3   1048.0        1045   1200.0   \n",
       "3  2008      8          25          1     23.0        2359    824.0   \n",
       "4  2008      4          27          7   2016.0        2010   2139.0   \n",
       "\n",
       "   CRSArrTime UniqueCarrier  FlightNum        ...         TaxiIn  TaxiOut  \\\n",
       "0        1142            EV       4761        ...            2.0     29.0   \n",
       "1        2356            NW        250        ...            4.0     30.0   \n",
       "2        1210            WN        664        ...            6.0      8.0   \n",
       "3         815            B6         88        ...            9.0     10.0   \n",
       "4        2139            US       1007        ...            6.0     20.0   \n",
       "\n",
       "   Cancelled  CancellationCode  Diverted  CarrierDelay WeatherDelay NASDelay  \\\n",
       "0          0               NaN         0           NaN          NaN      NaN   \n",
       "1          0               NaN         0          18.0          0.0     14.0   \n",
       "2          0               NaN         0           NaN          NaN      NaN   \n",
       "3          0               NaN         0           NaN          NaN      NaN   \n",
       "4          0               NaN         0           NaN          NaN      NaN   \n",
       "\n",
       "   SecurityDelay  LateAircraftDelay  \n",
       "0            NaN                NaN  \n",
       "1            0.0                5.0  \n",
       "2            NaN                NaN  \n",
       "3            NaN                NaN  \n",
       "4            NaN                NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = flights.reset_index(drop=True)\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year                      0\n",
      "Month                     0\n",
      "DayofMonth                0\n",
      "DayOfWeek                 0\n",
      "DepTime                6734\n",
      "CRSDepTime                0\n",
      "ArrTime                7538\n",
      "CRSArrTime                0\n",
      "UniqueCarrier             0\n",
      "FlightNum                 0\n",
      "TailNum                4143\n",
      "ActualElapsedTime      7702\n",
      "CRSElapsedTime           44\n",
      "AirTime                7702\n",
      "ArrDelay               7702\n",
      "DepDelay               6734\n",
      "Origin                    0\n",
      "Dest                      0\n",
      "Distance                  0\n",
      "TaxiIn                 7538\n",
      "TaxiOut                6784\n",
      "Cancelled                 0\n",
      "CancellationCode     343683\n",
      "Diverted                  0\n",
      "CarrierDelay         274306\n",
      "WeatherDelay         274306\n",
      "NASDelay             274306\n",
      "SecurityDelay        274306\n",
      "LateAircraftDelay    274306\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for nulls\n",
    "print(flights.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dont know if I want to drop the rows with null values in delay. But after looking 85% of these flights were cancelled (could be more given missing data) so its fair to assume that they are null bc they were cancelled. Seems like the other flights were divereted, so likely going to drop those as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights = flights[pd.notnull(flights['ArrDelay'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights = flights[flights.Cancelled != 1]\n",
    "flights = flights[flights.Diverted != 1]\n",
    "flights= flights.drop(['Cancelled','Diverted'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 342784 entries, 0 to 350485\n",
      "Data columns (total 27 columns):\n",
      "Year                 342784 non-null int64\n",
      "Month                342784 non-null int64\n",
      "DayofMonth           342784 non-null int64\n",
      "DayOfWeek            342784 non-null int64\n",
      "DepTime              342784 non-null float64\n",
      "CRSDepTime           342784 non-null int64\n",
      "ArrTime              342784 non-null float64\n",
      "CRSArrTime           342784 non-null int64\n",
      "UniqueCarrier        342784 non-null object\n",
      "FlightNum            342784 non-null int64\n",
      "TailNum              342784 non-null object\n",
      "ActualElapsedTime    342784 non-null float64\n",
      "CRSElapsedTime       342784 non-null float64\n",
      "AirTime              342784 non-null float64\n",
      "ArrDelay             342784 non-null float64\n",
      "DepDelay             342784 non-null float64\n",
      "Origin               342784 non-null object\n",
      "Dest                 342784 non-null object\n",
      "Distance             342784 non-null int64\n",
      "TaxiIn               342784 non-null float64\n",
      "TaxiOut              342784 non-null float64\n",
      "CancellationCode     0 non-null object\n",
      "CarrierDelay         76180 non-null float64\n",
      "WeatherDelay         76180 non-null float64\n",
      "NASDelay             76180 non-null float64\n",
      "SecurityDelay        76180 non-null float64\n",
      "LateAircraftDelay    76180 non-null float64\n",
      "dtypes: float64(14), int64(8), object(5)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "flights.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes sense now to drop Cancellation code and where the flight was cancelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights= flights.drop(['CancellationCode'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 unique values for Year\n",
      "There are 12 unique values for Month\n",
      "There are 31 unique values for DayofMonth\n",
      "There are 7 unique values for DayOfWeek\n",
      "There are 1372 unique values for DepTime\n",
      "There are 1168 unique values for CRSDepTime\n",
      "There are 1436 unique values for ArrTime\n",
      "There are 1330 unique values for CRSArrTime\n",
      "There are 20 unique values for UniqueCarrier\n",
      "There are 7413 unique values for FlightNum\n",
      "There are 5278 unique values for TailNum\n",
      "There are 571 unique values for ActualElapsedTime\n",
      "There are 482 unique values for CRSElapsedTime\n",
      "There are 554 unique values for AirTime\n",
      "There are 597 unique values for ArrDelay\n",
      "There are 563 unique values for DepDelay\n",
      "There are 300 unique values for Origin\n",
      "There are 301 unique values for Dest\n",
      "There are 1368 unique values for Distance\n",
      "There are 113 unique values for TaxiIn\n",
      "There are 227 unique values for TaxiOut\n",
      "There are 440 unique values for CarrierDelay\n",
      "There are 303 unique values for WeatherDelay\n",
      "There are 357 unique values for NASDelay\n",
      "There are 67 unique values for SecurityDelay\n",
      "There are 367 unique values for LateAircraftDelay\n"
     ]
    }
   ],
   "source": [
    "#likely going to want to drop other columns, so lets look at the data types and check for liekly categorical\n",
    "for col in flights.columns: \n",
    "    print('There are {} unique values for {}'.format((len(flights[col].unique())),col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dont need Year, but how should I handle month, dayofMonth, dayOfWeek\n",
    "\n",
    "Also, for the types of delay, should I look at the fraction?\n",
    "\n",
    "Also, will want to drop origin and dest as these are catgegorical, but it would take way to much computational power to create dummies. Unique carrier could be dummies. Same with flight and tail num\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights= flights.drop(['Year','Dest','Origin','FlightNum','TailNum',],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 342784 entries, 0 to 350485\n",
      "Data columns (total 21 columns):\n",
      "Month                342784 non-null int64\n",
      "DayofMonth           342784 non-null int64\n",
      "DayOfWeek            342784 non-null int64\n",
      "DepTime              342784 non-null float64\n",
      "CRSDepTime           342784 non-null int64\n",
      "ArrTime              342784 non-null float64\n",
      "CRSArrTime           342784 non-null int64\n",
      "UniqueCarrier        342784 non-null object\n",
      "ActualElapsedTime    342784 non-null float64\n",
      "CRSElapsedTime       342784 non-null float64\n",
      "AirTime              342784 non-null float64\n",
      "ArrDelay             342784 non-null float64\n",
      "DepDelay             342784 non-null float64\n",
      "Distance             342784 non-null int64\n",
      "TaxiIn               342784 non-null float64\n",
      "TaxiOut              342784 non-null float64\n",
      "CarrierDelay         76180 non-null float64\n",
      "WeatherDelay         76180 non-null float64\n",
      "NASDelay             76180 non-null float64\n",
      "SecurityDelay        76180 non-null float64\n",
      "LateAircraftDelay    76180 non-null float64\n",
      "dtypes: float64(14), int64(6), object(1)\n",
      "memory usage: 57.5+ MB\n"
     ]
    }
   ],
   "source": [
    "flights.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For the types of delays, I would want to remove all the null values. The shorter delays tend to have the more null values, \n",
    "#so let's assume that the type of delay is 'other' so we can replace the null values with 0\n",
    "cols = ['CarrierDelay','WeatherDelay','NASDelay','SecurityDelay',\n",
    "        'LateAircraftDelay']\n",
    "for i in cols:\n",
    "    flights[i] = flights[i].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#want to turn delay into indicator\n",
    "flights['ArrDelayInd'] = np.where(flights['ArrDelay'] > 30,1,0)\n",
    "flights = flights.drop(['ArrDelay'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    297412\n",
       "1     45372\n",
       "Name: ArrDelayInd, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check how many were delayed \n",
    "flights['ArrDelayInd'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow only 13% of flights were delayed. We will be dealing with class imbalance we would likely want to fix. \n",
    "We would likely want to down sample? \n",
    "@Vincent cna we go over? \n",
    "\n",
    "per vicent - when you train model, learn relationship between features and target, as well as learn distribution of outcpme var (whether one more common then the other, which is valuable). \n",
    "\n",
    "Run model first and run some subsampling to see if it makes model better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArrDelayInd          1.000000\n",
       "DepDelay             0.684936\n",
       "LateAircraftDelay    0.504109\n",
       "NASDelay             0.433202\n",
       "CarrierDelay         0.377119\n",
       "TaxiOut              0.291878\n",
       "DepTime              0.189259\n",
       "WeatherDelay         0.172276\n",
       "CRSDepTime           0.131860\n",
       "CRSArrTime           0.126867\n",
       "ActualElapsedTime    0.093182\n",
       "ArrTime              0.093077\n",
       "TaxiIn               0.088545\n",
       "AirTime              0.041141\n",
       "CRSElapsedTime       0.031160\n",
       "SecurityDelay        0.025075\n",
       "Distance             0.018812\n",
       "DayOfWeek            0.011401\n",
       "DayofMonth          -0.002252\n",
       "Month               -0.036813\n",
       "Name: ArrDelayInd, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat = flights.corr()\n",
    "\n",
    "corrmat['ArrDelayInd'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok rather than creating dummies for month, day of month, day of week, it might be easier to just remove them \n",
    "flights = flights.drop(['Month','DayofMonth','DayOfWeek'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = flights.copy()\n",
    "df = df.drop(['ArrDelayInd'],1)\n",
    "col_names = df.columns\n",
    "\n",
    "for name in col_names: \n",
    "    if 'Delay' in name: \n",
    "        df = df.drop([name], axis=1)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df= df.drop(['CancellationCode'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now im going to create dummies for carrier\n",
    "df2 = pd.get_dummies(df['UniqueCarrier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = pd.concat([df2, df], axis=1, join_axes=[df2.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 342784 entries, 0 to 350485\n",
      "Data columns (total 31 columns):\n",
      "9E                   342784 non-null uint8\n",
      "AA                   342784 non-null uint8\n",
      "AQ                   342784 non-null uint8\n",
      "AS                   342784 non-null uint8\n",
      "B6                   342784 non-null uint8\n",
      "CO                   342784 non-null uint8\n",
      "DL                   342784 non-null uint8\n",
      "EV                   342784 non-null uint8\n",
      "F9                   342784 non-null uint8\n",
      "FL                   342784 non-null uint8\n",
      "HA                   342784 non-null uint8\n",
      "MQ                   342784 non-null uint8\n",
      "NW                   342784 non-null uint8\n",
      "OH                   342784 non-null uint8\n",
      "OO                   342784 non-null uint8\n",
      "UA                   342784 non-null uint8\n",
      "US                   342784 non-null uint8\n",
      "WN                   342784 non-null uint8\n",
      "XE                   342784 non-null uint8\n",
      "YV                   342784 non-null uint8\n",
      "DepTime              342784 non-null float64\n",
      "CRSDepTime           342784 non-null int64\n",
      "ArrTime              342784 non-null float64\n",
      "CRSArrTime           342784 non-null int64\n",
      "UniqueCarrier        342784 non-null object\n",
      "ActualElapsedTime    342784 non-null float64\n",
      "CRSElapsedTime       342784 non-null float64\n",
      "AirTime              342784 non-null float64\n",
      "Distance             342784 non-null int64\n",
      "TaxiIn               342784 non-null float64\n",
      "TaxiOut              342784 non-null float64\n",
      "dtypes: float64(7), int64(3), object(1), uint8(20)\n",
      "memory usage: 37.9+ MB\n"
     ]
    }
   ],
   "source": [
    "feats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = feats.drop(['UniqueCarrier'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = feats.drop(['ArrDelayInd'],1)\n",
    "#scal\n",
    "\n",
    "# Select only numeric variables to scale.\n",
    "df_num = feats.select_dtypes(include=[np.number]).dropna()\n",
    "\n",
    "# Save the column names.\n",
    "names=df_num.columns\n",
    "\n",
    "# Scale, then turn the resulting numpy array back into a data frame with the correct column names.\n",
    "feats_scaled = pd.DataFrame(preprocessing.scale(df_num), columns=names, index=feats.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats_scaled['ArrDelayInd'] = flights['ArrDelayInd']\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X = feats_scaled.drop(['ArrDelayInd'], axis=1, inplace=False)\n",
    "# Dependent variable\n",
    "Y = feats_scaled['ArrDelayInd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Logistic Accuracy by ArrDelayInd\n",
      "ArrDelayInd      0     1\n",
      "row_0                   \n",
      "0            89166  6268\n",
      "1              135  7267\n",
      "\n",
      "The accuracy for train set:  0.9363778818744061\n",
      "The accuracy for test set:  0.9377358123614299\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "\n",
    "X_train, X_test, Y_train, Y_test =model_selection.train_test_split(X,Y, test_size=0.30, random_state=42) \n",
    "regr = LogisticRegression()\n",
    "# Fit the variables to the logistic model.\n",
    "regr.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = regr.predict(X_test)\n",
    "print('\\n Logistic Accuracy by ArrDelayInd')\n",
    "print(pd.crosstab(Y_pred, Y_test))\n",
    "\n",
    "print('\\nThe accuracy for train set: ',format(regr.score(X_train, Y_train)))\n",
    "print('The accuracy for test set: ',format(regr.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicting flight to be on time but it delayed\n",
    "\n",
    "learning over baseline model (predicting 87 % to be on time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficients: \n",
      " [[ -3.23904052e-02   5.53609262e-02  -3.13559388e-02  -1.53731755e-03\n",
      "    5.81817893e-03  -8.53200441e-03  -7.63409014e-02   2.68437286e-02\n",
      "   -3.44475137e-02  -1.19966061e-02  -6.77596801e-02   4.75076305e-02\n",
      "   -3.74782388e-02  -1.65794797e-02  -2.37951163e-02   4.93099586e-02\n",
      "   -5.92939620e-02   5.43225569e-02   1.58941419e-02   1.51232640e-02\n",
      "    1.10365670e+01  -1.03882937e+01  -1.17114933e-01   1.06937150e-01\n",
      "    2.20903836e+00  -4.02626371e+00   2.18814631e+00  -3.78959219e-01\n",
      "    1.83463370e-01   5.74253205e-01]]\n",
      "\n",
      "Intercept: \n",
      " [-2.59817196]\n"
     ]
    }
   ],
   "source": [
    "print('\\nCoefficients: \\n', regr.coef_)\n",
    "print('\\nIntercept: \\n', regr.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Each Cross Validated R2 score: \n",
      " [ 0.93550175  0.9367853   0.93981563  0.93681078  0.93529377  0.93593559\n",
      "  0.93546881  0.9364607   0.9349437   0.93517708]\n",
      "\n",
      "Overall Logistic Regression R2: 0.94 (+/- 0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(regr, X, Y, cv=10)\n",
    "print('\\nEach Cross Validated R2 score: \\n', score)\n",
    "print(\"\\nOverall Logistic Regression R2: %0.2f (+/- %0.2f)\\n\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0014253088169103305\n",
      "Percent Type II errors: 0.06219680930868355\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0013127698471352444\n",
      "Percent Type II errors: 0.060951417791434905\n"
     ]
    }
   ],
   "source": [
    "predict_train = regr.predict(X_train)\n",
    "predict_test = regr.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(Y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(Y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArrDelayInd          1.000000\n",
       "TaxiOut              0.291878\n",
       "DepTime              0.189259\n",
       "CRSDepTime           0.131860\n",
       "CRSArrTime           0.126867\n",
       "ActualElapsedTime    0.093182\n",
       "ArrTime              0.093077\n",
       "TaxiIn               0.088545\n",
       "AirTime              0.041141\n",
       "AA                   0.033746\n",
       "CRSElapsedTime       0.031160\n",
       "UA                   0.026892\n",
       "Distance             0.018812\n",
       "OH                   0.016491\n",
       "B6                   0.016045\n",
       "XE                   0.015883\n",
       "MQ                   0.015233\n",
       "YV                   0.014829\n",
       "CO                   0.012854\n",
       "EV                   0.010777\n",
       "FL                  -0.002576\n",
       "NW                  -0.007380\n",
       "AS                  -0.009221\n",
       "DL                  -0.009911\n",
       "AQ                  -0.010843\n",
       "OO                  -0.013416\n",
       "9E                  -0.013961\n",
       "F9                  -0.015782\n",
       "US                  -0.024311\n",
       "HA                  -0.025485\n",
       "WN                  -0.035896\n",
       "Name: ArrDelayInd, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat = feats_scaled.corr()\n",
    "\n",
    "corrmat['ArrDelayInd'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display\n",
    "# correlation_matrix = feats_scaled.corr()\n",
    "# display(np.where(correlation_matrix.values<1.0,correlation_matrix.values,0).max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty great. I am going to try a couple other models to see if they improve. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RF Accuracy by ArrDelayInd\n",
      "ArrDelayInd      0     1\n",
      "row_0                   \n",
      "0            88884  3741\n",
      "1              417  9794\n",
      "\n",
      "Accuracy on training set: 0.998\n",
      "\n",
      "Accuracy on test set: 0.960\n",
      "\n",
      "Each Cross Validated R2 score: \n",
      " [ 0.96308235  0.96054436  0.96149134  0.96500671  0.96440866]\n",
      "\n",
      "Overall Random Forest Regression R2: 0.96 (+/- 0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "X = feats_scaled.drop(['ArrDelayInd'], axis=1, inplace=False)\n",
    "# Dependent variable\n",
    "Y = feats_scaled['ArrDelayInd']\n",
    "X_train, X_test, Y_train, Y_test =model_selection.train_test_split(X,Y, test_size=0.30, random_state=42) \n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc.fit(X_train, Y_train)\n",
    "Y_pred = rfc.predict(X_test)\n",
    "\n",
    "print('\\n RF Accuracy by ArrDelayInd')\n",
    "print(pd.crosstab(Y_pred, Y_test))\n",
    "\n",
    "print(\"\\nAccuracy on training set: {:.3f}\".format(rfc.score(X_train, Y_train)))\n",
    "print(\"\\nAccuracy on test set: {:.3f}\".format(rfc.score(X_test, Y_test)))\n",
    "\n",
    "\n",
    "rfc_score = cross_val_score(rfc, X, Y, cv=5)\n",
    "print('\\nEach Cross Validated R2 score: \\n', rfc_score)\n",
    "print(\"\\nOverall Random Forest Regression R2: %0.2f (+/- %0.2f)\\n\" % (rfc_score.mean(), rfc_score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 5.417840532115292e-05\n",
      "Percent Type II errors: 0.0021004550986046975\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.004055000194484422\n",
      "Percent Type II errors: 0.03637831109728111\n"
     ]
    }
   ],
   "source": [
    "predict_train = rfc.predict(X_train)\n",
    "predict_test = rfc.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(Y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(Y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forrestdoes perform better, and reduces our type 1 error (and improves overall accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
